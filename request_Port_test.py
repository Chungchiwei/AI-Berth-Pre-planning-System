"""
æ¸¬è©¦èˆ¹æ³Šåœ°çˆ¬èŸ²
"""
from modules.anchored_ships_crawler import AnchoredShipsCrawler
import pandas as pd

def test_crawler():
    """æ¸¬è©¦çˆ¬èŸ²åŠŸèƒ½"""
    
    print("="*60)
    print("ğŸ§ª èˆ¹æ³Šåœ°çˆ¬èŸ²æ¸¬è©¦")
    print("="*60)
    
    # åˆå§‹åŒ–çˆ¬èŸ²
    crawler = AnchoredShipsCrawler(verbose=True)
    
    # æ¸¬è©¦ 1: å–å¾— CSRF Token
    print("\nã€æ¸¬è©¦ 1ã€‘å–å¾— CSRF Token")
    print("-"*60)
    if crawler.get_csrf_token():
        print(f"âœ… Token: {crawler.token[:30]}...")
        print(f"âœ… Token æ™‚é–“: {crawler.last_token_time}")
    else:
        print("âŒ Token å–å¾—å¤±æ•—")
        return
    
    # æ¸¬è©¦ 2: çˆ¬å–å–®ä¸€æ¸¯å£ï¼ˆè‡ºåŒ—æ¸¯ï¼‰
    print("\nã€æ¸¬è©¦ 2ã€‘çˆ¬å–è‡ºåŒ—æ¸¯è³‡æ–™")
    print("-"*60)
    df_tpe = crawler.fetch_anchored_ships('TPE')
    
    if not df_tpe.empty:
        print(f"âœ… æˆåŠŸçˆ¬å– {len(df_tpe)} ç­†è³‡æ–™")
        print(f"\nğŸ“Š è³‡æ–™æ¬„ä½:")
        print(df_tpe.columns.tolist())
        print(f"\nğŸ“‹ å‰ 3 ç­†è³‡æ–™:")
        print(df_tpe.head(3))
        
        # æª¢æŸ¥é—œéµæ¬„ä½
        print(f"\nğŸ” é—œéµæ¬„ä½æª¢æŸ¥:")
        key_columns = ['èˆ¹å_ä¸­æ–‡', 'èˆ¹å_è‹±æ–‡', 'éŒ¨æ³Šæ™‚é–“', 'èˆ¹èˆ¶é¡å‹', 'å™¸ä½']
        for col in key_columns:
            if col in df_tpe.columns:
                non_null = df_tpe[col].notna().sum()
                print(f"  âœ… {col}: {non_null}/{len(df_tpe)} ç­†æœ‰å€¼")
            else:
                print(f"  âŒ {col}: æ¬„ä½ä¸å­˜åœ¨")
        
        # è³‡æ–™å‹æ…‹æª¢æŸ¥
        print(f"\nğŸ“ è³‡æ–™å‹æ…‹:")
        print(df_tpe.dtypes)
        
    else:
        print("âš ï¸ è‡ºåŒ—æ¸¯ç›®å‰ç„¡èˆ¹æ³Šåœ°è³‡æ–™ï¼ˆæˆ–çˆ¬å–å¤±æ•—ï¼‰")
    
    # æ¸¬è©¦ 3: çˆ¬å–é«˜é›„æ¸¯
    print("\nã€æ¸¬è©¦ 3ã€‘çˆ¬å–é«˜é›„æ¸¯è³‡æ–™")
    print("-"*60)
    df_khh = crawler.fetch_anchored_ships('KHH')
    
    if not df_khh.empty:
        print(f"âœ… æˆåŠŸçˆ¬å– {len(df_khh)} ç­†è³‡æ–™")
        print(f"ğŸ“‹ å‰ 3 ç­†è³‡æ–™:")
        print(df_khh.head(3))
    else:
        print("âš ï¸ é«˜é›„æ¸¯ç›®å‰ç„¡èˆ¹æ³Šåœ°è³‡æ–™ï¼ˆæˆ–çˆ¬å–å¤±æ•—ï¼‰")
    
    # æ¸¬è©¦ 4: è³‡æ–™çµ±è¨ˆ
    print("\nã€æ¸¬è©¦ 4ã€‘è³‡æ–™çµ±è¨ˆ")
    print("-"*60)
    
    all_data = {}
    if not df_tpe.empty:
        all_data['è‡ºåŒ—æ¸¯'] = df_tpe
    if not df_khh.empty:
        all_data['é«˜é›„æ¸¯'] = df_khh
    
    if all_data:
        stats = crawler.get_statistics(all_data)
        print(f"ğŸ“Š çµ±è¨ˆçµæœ:")
        print(f"  ç¸½ç­†æ•¸: {stats['ç¸½ç­†æ•¸']}")
        print(f"  æ¸¯å£æ•¸: {stats['æ¸¯å£æ•¸']}")
        print(f"  å„æ¸¯å£çµ±è¨ˆ:")
        for port, info in stats['å„æ¸¯å£çµ±è¨ˆ'].items():
            print(f"    â€¢ {port}: {info['èˆ¹èˆ¶æ•¸']} è‰˜")
    
    # æ¸¬è©¦ 5: å„²å­˜ CSV
    print("\nã€æ¸¬è©¦ 5ã€‘å„²å­˜ CSV")
    print("-"*60)
    
    if all_data:
        saved_df = crawler.save_to_csv(
            all_data, 
            filename='test_anchored_ships.csv',
            output_dir='test_output'
        )
        
        if saved_df is not None:
            print(f"âœ… æˆåŠŸå„²å­˜ {len(saved_df)} ç­†è³‡æ–™")
        else:
            print("âŒ å„²å­˜å¤±æ•—")
    
    # æ¸¬è©¦ 6: Token éæœŸæª¢æŸ¥
    print("\nã€æ¸¬è©¦ 6ã€‘Token éæœŸæª¢æŸ¥")
    print("-"*60)
    
    is_expired = crawler._is_token_expired()
    print(f"Token æ˜¯å¦éæœŸ: {'æ˜¯' if is_expired else 'å¦'}")
    
    if crawler.last_token_time:
        from datetime import datetime
        elapsed = (datetime.now() - crawler.last_token_time).total_seconds()
        print(f"Token å·²å­˜åœ¨: {elapsed:.0f} ç§’")
    
    print("\n" + "="*60)
    print("ğŸ‰ æ¸¬è©¦å®Œæˆ")
    print("="*60)


def test_response_format():
    """æ¸¬è©¦ API å›æ‡‰æ ¼å¼"""
    
    print("\nã€é¡å¤–æ¸¬è©¦ã€‘API å›æ‡‰æ ¼å¼åˆ†æ")
    print("-"*60)
    
    crawler = AnchoredShipsCrawler(verbose=True)
    
    if not crawler.get_csrf_token():
        print("âŒ ç„¡æ³•å–å¾— Token")
        return
    
    import requests
    
    url = f"{crawler.base_url}/IFAWeb/Board/PortStatus/LoadAnchoredShips"
    
    payload = {
        'portId': 'TPE',
        'wharfType': '',
        'wharfCode': '',
        'shipGroup': '',
        'vesselNo': '',
        'vesselCname': '',
        'vesselEname': '',
        'registerNoI': '',
        'callSign': '',
        'startDt': '',
        '__RequestVerificationToken': crawler.token
    }
    
    try:
        response = crawler.session.post(url, data=payload, timeout=30)
        
        print(f"ç‹€æ…‹ç¢¼: {response.status_code}")
        print(f"Content-Type: {response.headers.get('Content-Type')}")
        
        if response.status_code == 200:
            data = response.json()
            
            print(f"\nğŸ“¦ å›æ‡‰è³‡æ–™çµæ§‹:")
            print(f"  é¡å‹: {type(data)}")
            
            if isinstance(data, dict):
                print(f"  Keys: {list(data.keys())}")
                
                # æª¢æŸ¥å¯èƒ½çš„è³‡æ–™ä½ç½®
                for key in ['data', 'result', 'items', 'ships', 'list']:
                    if key in data:
                        print(f"\n  âœ… æ‰¾åˆ°è³‡æ–™ key: '{key}'")
                        print(f"     é¡å‹: {type(data[key])}")
                        
                        if isinstance(data[key], list) and len(data[key]) > 0:
                            print(f"     ç­†æ•¸: {len(data[key])}")
                            print(f"     ç¬¬ä¸€ç­†è³‡æ–™ keys:")
                            print(f"     {list(data[key][0].keys())}")
            
            elif isinstance(data, list):
                print(f"  ç›´æ¥ç‚º listï¼Œç­†æ•¸: {len(data)}")
                if len(data) > 0:
                    print(f"  ç¬¬ä¸€ç­†è³‡æ–™ keys:")
                    print(f"  {list(data[0].keys())}")
            
            # é¡¯ç¤ºåŸå§‹å›æ‡‰ï¼ˆå‰ 500 å­—å…ƒï¼‰
            print(f"\nğŸ“„ åŸå§‹å›æ‡‰ï¼ˆå‰ 500 å­—å…ƒï¼‰:")
            print(response.text[:500])
        
        else:
            print(f"âŒ è«‹æ±‚å¤±æ•—: {response.status_code}")
            print(f"å›æ‡‰å…§å®¹: {response.text[:200]}")
    
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")


def test_all_ports():
    """æ¸¬è©¦æ‰€æœ‰æ¸¯å£"""
    
    print("\nã€å®Œæ•´æ¸¬è©¦ã€‘æ‰€æœ‰æ¸¯å£çˆ¬å–")
    print("="*60)
    
    crawler = AnchoredShipsCrawler(verbose=True)
    
    all_data = crawler.fetch_all_ports(delay=2.0)
    
    print("\nğŸ“Š æœ€çµ‚çµ±è¨ˆ:")
    print("-"*60)
    
    total_ships = 0
    for port_name, df in all_data.items():
        ship_count = len(df)
        total_ships += ship_count
        print(f"  {port_name}: {ship_count} è‰˜")
    
    print(f"\n  ç¸½è¨ˆ: {total_ships} è‰˜")
    
    # å„²å­˜åˆä½µè³‡æ–™
    if all_data:
        crawler.save_to_csv(
            all_data,
            filename='all_ports_anchored_ships.csv',
            output_dir='test_output'
        )


if __name__ == '__main__':
    # åŸ·è¡ŒåŸºæœ¬æ¸¬è©¦
    test_crawler()
    
    # åŸ·è¡Œ API æ ¼å¼æ¸¬è©¦
    test_response_format()
    
    # åŸ·è¡Œå®Œæ•´æ¸¬è©¦ï¼ˆå¯é¸ï¼ŒæœƒèŠ±è¼ƒé•·æ™‚é–“ï¼‰
    # test_all_ports()
