"""
è³‡æ–™åº«ç®¡ç†æ¨¡çµ„ - æ•´åˆä¿®æ­£ç‰ˆ
ç‰ˆæœ¬: 3.0
ä¿®æ­£: 
  1. é¿å…é‡è¤‡è³‡æ–™ï¼ˆUNIQUE ç´„æŸï¼‰
  2. æ–°å¢æ³Šä½å ç”¨è¨ˆç®—
  3. æ–°å¢è³‡æ–™æ¸…ç†åŠŸèƒ½
  4. ä¿ç•™åŸæœ‰ IFA è¡¨æ ¼çµæ§‹
  5. ç°¡åŒ–å¿«å–ç®¡ç†ï¼ˆç§»é™¤ç¨ç«‹å¿«å–è¡¨ï¼‰
"""
import sqlite3
import pandas as pd
from datetime import datetime, timedelta
import logging
import sys
from typing import Optional, List, Dict, Any  # âœ… åŠ å…¥ Optional
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import DB_PATH, CACHE_TTL_MINUTES, TIMEZONE
import pytz
from pathlib import Path
# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


def ensure_db_directory():
    """ç¢ºä¿è³‡æ–™åº«ç›®éŒ„å­˜åœ¨"""
    db_path = Path(DB_PATH)
    
    # å¦‚æœæ˜¯é›²ç«¯ç’°å¢ƒï¼Œ/tmp å·²å­˜åœ¨ï¼Œä¸éœ€å»ºç«‹
    if not os.getenv('STREAMLIT_SHARING_MODE'):
        db_path.parent.mkdir(parents=True, exist_ok=True)
        logger.info(f"âœ“ è³‡æ–™åº«ç›®éŒ„å·²ç¢ºèª: {db_path.parent}")
        
        
def get_db_connection():
    """
    å–å¾—è³‡æ–™åº«é€£ç·š
    
    Returns:
        sqlite3.Connection: è³‡æ–™åº«é€£ç·šç‰©ä»¶
    """
    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    ensure_db_directory()
    
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

def init_database():
    """åˆå§‹åŒ–è³‡æ–™åº«ï¼Œå»ºç«‹æ‰€æœ‰å¿…è¦çš„è¡¨æ ¼"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # ==================== IFA_D005: èˆ¹å¸­ç¾æ³åŠæŒ‡æ³Šè¡¨  ====================
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS ifa_d005 (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            
            -- åŸºæœ¬è³‡è¨Š
            port_code TEXT NOT NULL,
            port_name TEXT NOT NULL,           
            
            -- Row1 æ¬„ä½ (12 æ¬„)
            wharf_code TEXT,            -- ç¢¼é ­ç·¨è™Ÿ
            alongside_status TEXT,       -- ç¾é /æ¥é 
            mooring_type TEXT,           -- é æ³Šæ–¹å¼
            prev_wharf TEXT,             -- ç§»æ³Šå‰ç¢¼é ­
            vessel_no TEXT,              -- èˆ¹èˆ¶è™Ÿæ•¸
            ship_type TEXT,              -- èˆ¹ç¨®
            vessel_ename TEXT,           -- è‹±æ–‡èˆ¹å
            visa_no TEXT,                -- ç°½è­‰ç·¨è™Ÿ
            eta_berth TEXT,              -- é å®šé æ³Šæ™‚é–“
            etd_berth TEXT,              -- é å®šé›¢æ³Šæ™‚é–“
            prev_port TEXT,              -- å‰ä¸€æ¸¯
            isps_level TEXT,             -- ä¿å…¨ç­‰ç´š
            
            -- Row2 æ¬„ä½ (11 æ¬„ï¼Œå›  rowspan)
            wharf_name TEXT,             -- ç¢¼é ­åç¨±
            movement_status TEXT,        -- å‹•æ…‹
            via_port TEXT,               -- é€šéæ¸¯å£
            gt REAL,                     -- ç¸½å™¸
            arrival_purpose TEXT,        -- åˆ°æ¸¯ç›®çš„
            vessel_cname TEXT,           -- ä¸­æ–‡èˆ¹å
            agent TEXT,                  -- æ¸¯å£ä»£ç†
            ata_berth TEXT,              -- å¯¦éš›é æ³Šæ™‚é–“
            eta_pilot TEXT,              -- é å®šå¼•æ°´æ™‚é–“
            next_port TEXT,              -- æ¬¡ä¸€æ¸¯
            loa_m REAL,                  -- èˆ¹èˆ¶ç¸½é•·
            
            -- é¡å¤–æ¬„ä½
            can_berth_container INTEGER DEFAULT 0,
            crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            saved_at TEXT,
            
            -- ğŸ”¥ å”¯ä¸€æ€§ç´„æŸï¼šé¿å…é‡è¤‡è³‡æ–™
            UNIQUE(port_code, wharf_code, vessel_ename, eta_berth, crawled_at)
        )
        """)

        # ==================== ifa_d003: é€²æ¸¯èˆ¹èˆ¶è¡¨ (11+11 æ¬„ä½) ====================
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS ifa_d003 (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            
            -- åŸºæœ¬è³‡è¨Š
            port_code TEXT NOT NULL,
            port_name TEXT NOT NULL,
            
            -- Row1 æ¬„ä½ (11 æ¬„)
            call_sign TEXT,              -- èˆ¹èˆ¶å‘¼è™Ÿ
            ship_type TEXT,              -- èˆ¹ç¨®
            vessel_ename TEXT,           -- è‹±æ–‡èˆ¹å
            visa_no TEXT,                -- ç°½è­‰ç·¨è™Ÿ
            eta_report TEXT,             -- é å ±é€²æ¸¯æ™‚é–“
            eta_berth TEXT,              -- é å®šé æ³Šæ™‚é–“
            berth TEXT,                  -- é æ³Šç¢¼é ­
            prev_port TEXT,              -- å‰ä¸€æ¸¯
            vhf_report_time TEXT,        -- VHFå ±åˆ°æ™‚é–“
            loa_m REAL,                  -- èˆ¹é•·(M)
            anchor_time TEXT,            -- ä¸‹éŒ¨æ™‚é–“
            
            -- Row2 æ¬„ä½ (11 æ¬„)
            imo TEXT,                    -- IMO
            agent TEXT,                  -- æ¸¯å£ä»£ç†
            vessel_cname TEXT,           -- ä¸­æ–‡èˆ¹å
            arrival_purpose TEXT,        -- åˆ°æ¸¯ç›®çš„
            inport_pass_time TEXT,       -- é€²æ¸¯é€šéæ¸¯å£æ™‚é–“
            etd_berth TEXT,              -- é å®šé›¢æ³Šæ™‚é–“
            ata_berth TEXT,              -- é æ³Šæ™‚é–“
            next_port TEXT,              -- æ¬¡ä¸€æ¸¯
            captain_report_eta TEXT,     -- èˆ¹é•·å ±åˆ°ETA
            gt REAL,                     -- ç¸½å™¸
            inport_5nm_time TEXT,        -- é€²æ¸¯é€šé5æµ¬æ™‚é–“
            
            -- é¡å¤–æ¬„ä½
            can_berth_container INTEGER DEFAULT 0,
            crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            saved_at TEXT,
            
            -- ğŸ”¥ å”¯ä¸€æ€§ç´„æŸï¼šé¿å…é‡è¤‡è³‡æ–™
            UNIQUE(port_code, vessel_ename, eta_berth, crawled_at)
        )
        """)

        # ==================== ifa_d004: å‡ºæ¸¯èˆ¹èˆ¶è¡¨ (9+8 æ¬„ä½) ====================
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS ifa_d004 (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            
            -- åŸºæœ¬è³‡è¨Š
            port_code TEXT NOT NULL,
            port_name TEXT NOT NULL,
            
            -- Row1 æ¬„ä½ (9 æ¬„)
            call_sign TEXT,              -- èˆ¹èˆ¶å‘¼è™Ÿ
            ship_type TEXT,              -- èˆ¹ç¨®
            vessel_ename TEXT,           -- è‹±æ–‡èˆ¹å
            visa_no TEXT,                -- ç°½è­‰ç·¨è™Ÿ
            etd_report TEXT,             -- é å ±å‡ºæ¸¯æ™‚é–“
            etd_berth TEXT,              -- é å®šé›¢æ³Šæ™‚é–“ (rowspan)
            berth TEXT,                  -- é æ³Šç¢¼é ­
            prev_port TEXT,              -- å‰ä¸€æ¸¯
            isps_level TEXT,             -- ä¿å…¨ç­‰ç´š
            
            -- Row2 æ¬„ä½ (8 æ¬„ï¼Œå›  rowspan)
            imo TEXT,                    -- IMO
            agent TEXT,                  -- æ¸¯å£ä»£ç†
            vessel_cname TEXT,           -- ä¸­æ–‡èˆ¹å
            arrival_purpose TEXT,        -- åˆ°æ¸¯ç›®çš„
            outport_pass_time TEXT,      -- å‡ºæ¸¯é€šéæ¸¯å£æ™‚é–“
            atd_berth TEXT,              -- é›¢æ³Šæ™‚é–“
            next_port TEXT,              -- æ¬¡ä¸€æ¸¯
            loa_m REAL,                  -- èˆ¹é•·(M)
            
            -- é¡å¤–æ¬„ä½
            can_berth_container INTEGER DEFAULT 0,
            crawled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            saved_at TEXT,
            
            -- ğŸ”¥ å”¯ä¸€æ€§ç´„æŸï¼šé¿å…é‡è¤‡è³‡æ–™
            UNIQUE(port_code, vessel_ename, etd_berth, crawled_at)
        )
        """)

        # ===== å»ºç«‹ç´¢å¼• =====
        
        indexes = [
            # D005 ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_d005_port ON ifa_d005(port_code, port_name)",
            "CREATE INDEX IF NOT EXISTS idx_d005_wharf ON ifa_d005(wharf_code, wharf_name)",
            "CREATE INDEX IF NOT EXISTS idx_d005_vessel ON ifa_d005(vessel_ename, vessel_cname)",
            "CREATE INDEX IF NOT EXISTS idx_d005_time ON ifa_d005(eta_berth, etd_berth)",
            "CREATE INDEX IF NOT EXISTS idx_d005_status ON ifa_d005(alongside_status, movement_status)",
            "CREATE INDEX IF NOT EXISTS idx_d005_container ON ifa_d005(can_berth_container)",
            "CREATE INDEX IF NOT EXISTS idx_d005_crawled_at ON ifa_d005(crawled_at)",
            "CREATE INDEX IF NOT EXISTS idx_d005_ship_type ON ifa_d005(ship_type)",
            
            # D003 ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_d003_port ON ifa_d003(port_code, port_name)",
            "CREATE INDEX IF NOT EXISTS idx_d003_vessel ON ifa_d003(vessel_ename, vessel_cname)",
            "CREATE INDEX IF NOT EXISTS idx_d003_eta ON ifa_d003(eta_berth, eta_report)",
            "CREATE INDEX IF NOT EXISTS idx_d003_port_route ON ifa_d003(prev_port, next_port)",
            "CREATE INDEX IF NOT EXISTS idx_d003_container ON ifa_d003(can_berth_container)",
            "CREATE INDEX IF NOT EXISTS idx_d003_crawled_at ON ifa_d003(crawled_at)",
            "CREATE INDEX IF NOT EXISTS idx_d003_ship_type ON ifa_d003(ship_type)",
            "CREATE INDEX IF NOT EXISTS idx_d003_berth ON ifa_d003(berth)",
            
            # D004 ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_d004_port ON ifa_d004(port_code, port_name)",
            "CREATE INDEX IF NOT EXISTS idx_d004_vessel ON ifa_d004(vessel_ename, vessel_cname)",
            "CREATE INDEX IF NOT EXISTS idx_d004_etd ON ifa_d004(etd_berth, etd_report)",
            "CREATE INDEX IF NOT EXISTS idx_d004_next_port ON ifa_d004(next_port)",
            "CREATE INDEX IF NOT EXISTS idx_d004_container ON ifa_d004(can_berth_container)",
            "CREATE INDEX IF NOT EXISTS idx_d004_crawled_at ON ifa_d004(crawled_at)",
            "CREATE INDEX IF NOT EXISTS idx_d004_ship_type ON ifa_d004(ship_type)",
            "CREATE INDEX IF NOT EXISTS idx_d004_berth ON ifa_d004(berth)",
        ]
        
        for index_sql in indexes:
            cursor.execute(index_sql)

        conn.commit()
        logger.info("âœ“ è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")
        
    except sqlite3.Error as e:
        logger.error(f"âœ— è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
        conn.rollback()
        raise
    finally:
        conn.close()


def migrate_database():
    """
    è³‡æ–™åº«é·ç§»ï¼šæ–°å¢ç¼ºå¤±çš„æ¬„ä½
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    try:
        # ==================== D005 é·ç§» ====================
        d005_migrations = [
            ('port_code', 'TEXT NOT NULL DEFAULT ""'),
            ('port_name', 'TEXT NOT NULL DEFAULT ""'),
            ('can_berth_container', 'INTEGER DEFAULT 0'),
            ('alongside_status', 'TEXT'),
            ('mooring_type', 'TEXT'),
            ('prev_wharf', 'TEXT'),
            ('vessel_no', 'TEXT'),
            ('movement_status', 'TEXT'),
            ('via_port', 'TEXT'),
            ('isps_level', 'TEXT'),
            ('saved_at', 'TEXT'),
        ]
        
        # ==================== D003 é·ç§» ====================
        d003_migrations = [
            ('port_code', 'TEXT NOT NULL DEFAULT ""'),
            ('port_name', 'TEXT NOT NULL DEFAULT ""'),
            ('can_berth_container', 'INTEGER DEFAULT 0'),
            ('eta_report', 'TEXT'),
            ('vhf_report_time', 'TEXT'),
            ('anchor_time', 'TEXT'),
            ('inport_pass_time', 'TEXT'),
            ('captain_report_eta', 'TEXT'),
            ('inport_5nm_time', 'TEXT'),
            ('ata_berth', 'TEXT'),
            ('etd_berth', 'TEXT'),
            ('saved_at', 'TEXT'),
        ]
        
        # ==================== D004 é·ç§» ====================
        d004_migrations = [
            ('port_code', 'TEXT NOT NULL DEFAULT ""'),
            ('port_name', 'TEXT NOT NULL DEFAULT ""'),
            ('can_berth_container', 'INTEGER DEFAULT 0'),
            ('etd_report', 'TEXT'),
            ('outport_pass_time', 'TEXT'),
            ('atd_berth', 'TEXT'),
            ('saved_at', 'TEXT'),
        ]
        
        migrations = {
            'ifa_d005': d005_migrations,
            'ifa_d003': d003_migrations,
            'ifa_d004': d004_migrations,
        }
        
        for table, columns in migrations.items():
            # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name=?
            """, (table,))
            
            if not cursor.fetchone():
                logger.warning(f"âš  è¡¨æ ¼ {table} ä¸å­˜åœ¨ï¼Œè·³éé·ç§»")
                continue
            
            # å–å¾—ç¾æœ‰æ¬„ä½
            cursor.execute(f"PRAGMA table_info({table})")
            existing_columns = [row[1] for row in cursor.fetchall()]
            
            # æ–°å¢ç¼ºå¤±çš„æ¬„ä½
            for column_name, column_type in columns:
                if column_name not in existing_columns:
                    logger.info(f"æ­£åœ¨ç‚º {table} æ–°å¢ {column_name} æ¬„ä½...")
                    try:
                        cursor.execute(f"""
                            ALTER TABLE {table} 
                            ADD COLUMN {column_name} {column_type}
                        """)
                        conn.commit()
                        logger.info(f"âœ“ {table}: å·²æ–°å¢ {column_name} æ¬„ä½")
                    except sqlite3.Error as e:
                        logger.error(f"âœ— {table}: æ–°å¢ {column_name} å¤±æ•— - {e}")
                else:
                    logger.debug(f"âœ“ {table}: {column_name} æ¬„ä½å·²å­˜åœ¨")
        
        logger.info("âœ“ è³‡æ–™åº«é·ç§»å®Œæˆ")
        
    except sqlite3.Error as e:
        logger.error(f"âœ— è³‡æ–™åº«é·ç§»å¤±æ•—: {e}")
        conn.rollback()
        raise
    
    finally:
        conn.close()

def save_to_database(df: pd.DataFrame, table_name: str, port_code: str = None) -> bool:
    """
    å„²å­˜ DataFrame åˆ° SQLite è³‡æ–™åº«
    
    Args:
        df: è¦å„²å­˜çš„ DataFrame
        table_name: è³‡æ–™è¡¨åç¨± (ä¾‹å¦‚: 'ifa_d005', 'ifa_d003', 'ifa_d004')
        port_code: æ¸¯å£ä»£ç¢¼ (ä¾‹å¦‚: 'KEL', 'KHH')ï¼Œå¯é¸åƒæ•¸
    
    Returns:
        bool: å„²å­˜æ˜¯å¦æˆåŠŸ
    """
    if df is None or df.empty:
        print(f"âš ï¸  DataFrame ç‚ºç©ºï¼Œè·³éå„²å­˜")
        return False
    
    try:
        from pathlib import Path
        
        # ç¢ºä¿è³‡æ–™åº«ç›®éŒ„å­˜åœ¨
        db_path = Path(DB_PATH)
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è¤‡è£½ DataFrame é¿å…ä¿®æ”¹åŸå§‹è³‡æ–™
        df_to_save = df.copy()
        
        # âœ… æ·»åŠ  port_code æ¬„ä½ï¼ˆå¦‚æœæä¾›ä¸”ä¸å­˜åœ¨ï¼‰
        if port_code and 'port_code' not in df_to_save.columns:
            df_to_save['port_code'] = port_code
        
        # æ·»åŠ æ™‚é–“æˆ³è¨˜
        if 'saved_at' not in df_to_save.columns:
            df_to_save['saved_at'] = datetime.now(pytz.timezone(TIMEZONE)).isoformat()
        
        if 'crawled_at' not in df_to_save.columns:
            df_to_save['crawled_at'] = datetime.now(pytz.timezone(TIMEZONE)).isoformat()
        
        # é€£æ¥è³‡æ–™åº«
        conn = sqlite3.connect(DB_PATH)
        
        # å„²å­˜åˆ°è³‡æ–™åº«ï¼ˆè¿½åŠ æ¨¡å¼ï¼Œå¿½ç•¥é‡è¤‡ï¼‰
        try:
            df_to_save.to_sql(
                name=table_name,
                con=conn,
                if_exists='append',
                index=False
            )
            conn.commit()
            print(f"âœ… æˆåŠŸå„²å­˜ {len(df_to_save)} ç­†è³‡æ–™åˆ° {table_name}")
            return True
            
        except sqlite3.IntegrityError as e:
            # å¦‚æœæœ‰é‡è¤‡è³‡æ–™ï¼Œé€ç­†æ’å…¥ä¸¦è·³éé‡è¤‡
            print(f"âš ï¸  åµæ¸¬åˆ°é‡è¤‡è³‡æ–™ï¼Œæ­£åœ¨é€ç­†æ’å…¥...")
            
            cursor = conn.cursor()
            success_count = 0
            duplicate_count = 0
            
            for _, row in df_to_save.iterrows():
                try:
                    placeholders = ', '.join(['?' for _ in row])
                    columns = ', '.join(row.index)
                    sql = f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})"
                    cursor.execute(sql, tuple(row))
                    success_count += 1
                except sqlite3.IntegrityError:
                    duplicate_count += 1
                    continue
            
            conn.commit()
            print(f"âœ… æˆåŠŸå„²å­˜ {success_count} ç­†è³‡æ–™ï¼Œè·³é {duplicate_count} ç­†é‡è¤‡è³‡æ–™")
            return True
        
    except Exception as e:
        print(f"âŒ å„²å­˜å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        if 'conn' in locals():
            conn.close()

def query_latest_data(table_name: str, port_code: str = None, limit: int = 100) -> pd.DataFrame:
    """
    æŸ¥è©¢æœ€æ–°çš„è³‡æ–™
    
    Args:
        table_name: è¡¨æ ¼åç¨±
        port_code: æ¸¯å£ä»£ç¢¼ï¼ˆå¯é¸ï¼‰
        limit: é™åˆ¶ç­†æ•¸
    
    Returns:
        pd.DataFrame: æŸ¥è©¢çµæœ
    """
    conn = get_db_connection()
    
    try:
        if port_code:
            query = f"""
            SELECT * FROM {table_name}
            WHERE port_code = ?
            ORDER BY crawled_at DESC
            LIMIT ?
            """
            df = pd.read_sql_query(query, conn, params=(port_code, limit))
        else:
            query = f"""
            SELECT * FROM {table_name}
            ORDER BY crawled_at DESC
            LIMIT ?
            """
            df = pd.read_sql_query(query, conn, params=(limit,))
        
        logger.info(f"âœ“ {table_name}: æŸ¥è©¢åˆ° {len(df)} ç­†è³‡æ–™")
        return df
        
    except sqlite3.Error as e:
        logger.error(f"âœ— {table_name}: æŸ¥è©¢å¤±æ•— - {e}")
        return pd.DataFrame()
    
    finally:
        conn.close()

def is_cache_valid(table_name: str, port_code: str, cache_hours: float = None) -> bool:
    """
    æª¢æŸ¥å¿«å–æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        table_name: è¡¨æ ¼åç¨±
        port_code: æ¸¯å£ä»£ç¢¼
        cache_hours: å¿«å–æœ‰æ•ˆæ™‚é–“ï¼ˆå°æ™‚ï¼‰ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨ CACHE_TTL_MINUTES
    
    Returns:
        bool: å¿«å–æ˜¯å¦æœ‰æ•ˆ
    """
    conn = get_db_connection()
    
    try:
        query = f"""
        SELECT MAX(crawled_at) as latest_time
        FROM {table_name}
        WHERE port_code = ?
        """
        
        cursor = conn.cursor()
        cursor.execute(query, (port_code,))
        result = cursor.fetchone()
        
        if result and result['latest_time']:
            # ğŸ”¥ ä¿®æ­£ï¼šçµ±ä¸€ä½¿ç”¨å¸¶æ™‚å€çš„ datetime
            latest_time_str = result['latest_time']
            
            # å˜—è©¦è§£ææ™‚é–“å­—ä¸²
            try:
                # å¦‚æœæ˜¯ ISO æ ¼å¼ä¸”åŒ…å«æ™‚å€è³‡è¨Š
                latest_time = datetime.fromisoformat(latest_time_str)
                
                # å¦‚æœæ˜¯ naive datetimeï¼ŒåŠ ä¸Šæ™‚å€
                if latest_time.tzinfo is None:
                    latest_time = pytz.timezone(TIMEZONE).localize(latest_time)
                
            except Exception as e:
                logger.warning(f"è§£ææ™‚é–“å¤±æ•—: {latest_time_str}, éŒ¯èª¤: {e}")
                return False
            
            # ä½¿ç”¨å¸¶æ™‚å€çš„ç•¶å‰æ™‚é–“
            now = datetime.now(pytz.timezone(TIMEZONE))
            
            # è¨ˆç®—æ™‚é–“å·®
            age_minutes = (now - latest_time).total_seconds() / 60
            
            # å¦‚æœæœ‰æŒ‡å®š cache_hoursï¼Œä½¿ç”¨å®ƒï¼›å¦å‰‡ä½¿ç”¨ CACHE_TTL_MINUTES
            if cache_hours is not None:
                threshold_minutes = cache_hours * 60
            else:
                threshold_minutes = CACHE_TTL_MINUTES
            
            is_valid = age_minutes < threshold_minutes
            
            logger.debug(
                f"å¿«å–æª¢æŸ¥ - {table_name}@{port_code}: "
                f"å¹´é½¡={age_minutes:.1f}åˆ†é˜, "
                f"é–¾å€¼={threshold_minutes:.1f}åˆ†é˜, "
                f"æœ‰æ•ˆ={is_valid}"
            )
            
            return is_valid
        
        logger.debug(f"å¿«å–æª¢æŸ¥ - {table_name}@{port_code}: ç„¡è³‡æ–™")
        return False
        
    except sqlite3.Error as e:
        logger.error(f"âœ— æª¢æŸ¥å¿«å–å¤±æ•—: {e}")
        return False
    
    finally:
        conn.close()

def get_cache_age(table_name: str, port_code: str) -> Optional[float]:
    """
    å–å¾—å¿«å–å¹´é½¡ï¼ˆåˆ†é˜ï¼‰
    
    Args:
        table_name: è³‡æ–™è¡¨åç¨± (ifa_d005, ifa_d003, ifa_d004)
        port_code: æ¸¯å£ä»£ç¢¼
    
    Returns:
        å¿«å–å¹´é½¡ï¼ˆåˆ†é˜ï¼‰ï¼Œå¦‚æœç„¡è³‡æ–™å‰‡å›å‚³ None
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # âœ… ä¿®æ­£ï¼šä½¿ç”¨ crawled_at è€Œé crawl_time
        cursor.execute(f"""
            SELECT MAX(crawled_at) 
            FROM {table_name} 
            WHERE port_code = ?
        """, (port_code,))
        
        result = cursor.fetchone()
        latest_time = result[0] if result else None
        
        conn.close()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™
        if latest_time is None:
            print(f"[DEBUG] {table_name} ç„¡å¿«å–è³‡æ–™")
            return None
        
        # è§£ææ™‚é–“
        if isinstance(latest_time, str):
            # è™•ç†å¯èƒ½çš„æ™‚å€æ ¼å¼
            latest_time = latest_time.replace('Z', '+00:00')
            latest_dt = datetime.fromisoformat(latest_time)
        else:
            latest_dt = latest_time
        
        # ç¢ºä¿æœ‰æ™‚å€
        if latest_dt.tzinfo is None:
            latest_dt = pytz.timezone(TIMEZONE).localize(latest_dt)
        
        # è¨ˆç®—æ™‚é–“å·®ï¼ˆåˆ†é˜ï¼‰
        now = datetime.now(pytz.timezone(TIMEZONE))
        age_minutes = (now - latest_dt).total_seconds() / 60
        
        print(f"[DEBUG] {table_name} å¿«å–å¹´é½¡: {age_minutes:.1f} åˆ†é˜")
        
        return age_minutes
        
    except Exception as e:
        print(f"[ERROR] å–å¾—å¿«å–å¹´é½¡å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


def clear_old_data(table_name: str, days: int = 7) -> bool:
    """
    æ¸…é™¤èˆŠè³‡æ–™
    
    Args:
        table_name: è¡¨æ ¼åç¨±
        days: ä¿ç•™å¤©æ•¸
    
    Returns:
        bool: æ˜¯å¦æ¸…é™¤æˆåŠŸ
    """
    conn = get_db_connection()
    
    try:
        cursor = conn.cursor()
        
        # ğŸ”¥ ä¿®æ­£ï¼šä½¿ç”¨å¸¶æ™‚å€çš„ datetime
        now = datetime.now(pytz.timezone(TIMEZONE))
        cutoff_date = now - timedelta(days=days)
        
        # åˆªé™¤èˆŠè³‡æ–™
        cursor.execute(f"""
            DELETE FROM {table_name}
            WHERE crawled_at < ?
        """, (cutoff_date.isoformat(),))
        
        deleted_count = cursor.rowcount
        
        conn.commit()
        logger.info(f"âœ“ {table_name}: å·²æ¸…é™¤ {deleted_count} ç­†è¶…é {days} å¤©çš„èˆŠè³‡æ–™")
        return True
        
    except sqlite3.Error as e:
        logger.error(f"âœ— {table_name}: æ¸…é™¤èˆŠè³‡æ–™å¤±æ•— - {e}")
        conn.rollback()
        return False
    
    finally:
        conn.close()

def clear_all_data(table_name: str = None) -> bool:
    """
    æ¸…ç©ºæŒ‡å®šè¡¨æ ¼æˆ–æ‰€æœ‰è¡¨æ ¼
    
    Args:
        table_name: è¡¨æ ¼åç¨±ï¼ˆè‹¥ç‚º None å‰‡æ¸…ç©ºæ‰€æœ‰è¡¨æ ¼ï¼‰
    
    Returns:
        bool: æ˜¯å¦æ¸…é™¤æˆåŠŸ
    """
    conn = get_db_connection()
    
    try:
        cursor = conn.cursor()
        
        if table_name:
            tables = [table_name]
        else:
            tables = ['ifa_d005', 'ifa_d003', 'ifa_d004']
        
        for table in tables:
            cursor.execute(f"DELETE FROM {table}")
            deleted_count = cursor.rowcount
            logger.info(f"âœ“ {table}: å·²æ¸…ç©º {deleted_count} ç­†è³‡æ–™")
        
        conn.commit()
        return True
        
    except sqlite3.Error as e:
        logger.error(f"âœ— æ¸…ç©ºè³‡æ–™å¤±æ•—: {e}")
        conn.rollback()
        return False
    
    finally:
        conn.close()

def remove_duplicate_records(table_name: str = None) -> dict:
    """
    ğŸ”¥ ç§»é™¤é‡è¤‡è¨˜éŒ„ï¼ˆä¿ç•™æœ€æ–°ï¼‰
    
    Args:
        table_name: è¡¨æ ¼åç¨±ï¼ˆè‹¥ç‚º None å‰‡è™•ç†æ‰€æœ‰è¡¨æ ¼ï¼‰
    
    Returns:
        dict: å„è¡¨æ ¼åˆªé™¤çš„è¨˜éŒ„æ•¸
    """
    conn = get_db_connection()
    
    try:
        cursor = conn.cursor()
        
        if table_name:
            tables = [table_name]
        else:
            tables = ['ifa_d005', 'ifa_d003', 'ifa_d004']
        
        results = {}
        
        for table in tables:
            # æ ¹æ“šä¸åŒè¡¨æ ¼ä½¿ç”¨ä¸åŒçš„å”¯ä¸€æ€§æ¢ä»¶
            if table == 'ifa_d005':
                unique_cols = 'port_code, wharf_code, vessel_ename, eta_berth'
            elif table == 'ifa_d003':
                unique_cols = 'port_code, vessel_ename, eta_berth'
            elif table == 'ifa_d004':
                unique_cols = 'port_code, vessel_ename, etd_berth'
            else:
                continue
            
            # åˆªé™¤é‡è¤‡è¨˜éŒ„ï¼ˆä¿ç•™æœ€æ–°çš„ idï¼‰
            cursor.execute(f"""
                DELETE FROM {table}
                WHERE id NOT IN (
                    SELECT MAX(id)
                    FROM {table}
                    GROUP BY {unique_cols}
                )
            """)
            
            deleted_count = cursor.rowcount
            results[table] = deleted_count
            
            logger.info(f"âœ“ {table}: å·²ç§»é™¤ {deleted_count} ç­†é‡è¤‡è¨˜éŒ„")
        
        conn.commit()
        return results
        
    except sqlite3.Error as e:
        logger.error(f"âœ— ç§»é™¤é‡è¤‡è¨˜éŒ„å¤±æ•—: {e}")
        conn.rollback()
        return {}
    
    finally:
        conn.close()

def calculate_berth_occupancy(port_code: str, wharf_code: str = None) -> dict:
    """
    ğŸ”¥ è¨ˆç®—æ³Šä½å ç”¨æƒ…æ³ï¼ˆä¿®æ­£ç‰ˆï¼‰
    
    Args:
        port_code: æ¸¯å£ä»£ç¢¼
        wharf_code: ç¢¼é ­ä»£ç¢¼ï¼ˆå¯é¸ï¼Œè‹¥ç‚º None å‰‡è¨ˆç®—æ‰€æœ‰ç¢¼é ­ï¼‰
    
    Returns:
        dict: å ç”¨æƒ…æ³çµ±è¨ˆ
    """
    conn = get_db_connection()
    
    try:
        cursor = conn.cursor()
        
        # æŸ¥è©¢æ¢ä»¶
        if wharf_code:
            where_clause = "WHERE port_code = ? AND wharf_code = ?"
            params = (port_code, wharf_code)
        else:
            where_clause = "WHERE port_code = ?"
            params = (port_code,)
        
        # æŸ¥è©¢ç•¶å‰åœæ³Šèˆ¹èˆ¶ï¼ˆå»é‡ï¼‰
        query = f"""
        SELECT DISTINCT 
            wharf_code,
            wharf_name,
            vessel_ename,
            loa_m,
            alongside_status
        FROM ifa_d005
        {where_clause}
        AND alongside_status IN ('ç¾é ', 'æ¥é ')
        AND (etd_berth IS NULL OR etd_berth > datetime('now'))
        ORDER BY wharf_code, eta_berth
        """
        
        cursor.execute(query, params)
        ships = cursor.fetchall()
        
        # æŒ‰ç¢¼é ­åˆ†çµ„è¨ˆç®—
        berth_stats = {}
        
        for ship in ships:
            wharf = ship['wharf_code']
            
            if wharf not in berth_stats:
                berth_stats[wharf] = {
                    'wharf_name': ship['wharf_name'],
                    'ships': [],
                    'total_ship_length': 0,
                    'ship_count': 0
                }
            
            ship_length = ship['loa_m'] or 0
            
            berth_stats[wharf]['ships'].append({
                'vessel_ename': ship['vessel_ename'],
                'loa_m': ship_length,
                'status': ship['alongside_status']
            })
            
            berth_stats[wharf]['total_ship_length'] += ship_length
            berth_stats[wharf]['ship_count'] += 1
        
        # è¨ˆç®—å ç”¨é•·åº¦ï¼ˆåŠ å…¥å®‰å…¨è·é›¢ï¼‰
        for wharf, stats in berth_stats.items():
            ship_count = stats['ship_count']
            
            # å ç”¨é•·åº¦ = èˆ¹é•·ç¸½å’Œ + èˆ¹é–“è·ï¼ˆæ¯è‰˜èˆ¹å‰å¾Œå„ 10mï¼‰
            if ship_count > 0:
                occupied_length = stats['total_ship_length'] + (ship_count * 20) - 10
            else:
                occupied_length = 0
            
            stats['occupied_length'] = round(occupied_length, 1)
        
        return berth_stats
        
    except sqlite3.Error as e:
        logger.error(f"âœ— è¨ˆç®—æ³Šä½å ç”¨å¤±æ•—: {e}")
        return {}
    
    finally:
        conn.close()
def load_data_from_db(table_name: str, port_code: str) -> pd.DataFrame:
    """
    å¾è³‡æ–™åº«è¼‰å…¥è³‡æ–™
    
    Args:
        table_name: è³‡æ–™è¡¨åç¨± (ifa_d005, ifa_d003, ifa_d004)
        port_code: æ¸¯å£ä»£ç¢¼
    
    Returns:
        DataFrame
    """
    try:
        conn = get_db_connection()
        
        # âœ… ä¿®æ­£ï¼šä½¿ç”¨ crawled_at è€Œé crawl_time
        query = f"""
            SELECT * FROM {table_name}
            WHERE port_code = ?
            ORDER BY crawled_at DESC
        """
        
        df = pd.read_sql_query(query, conn, params=(port_code,))
        conn.close()
        
        print(f"[INFO] å¾è³‡æ–™åº«è¼‰å…¥ {len(df)} ç­† {table_name} è³‡æ–™")
        
        return df
        
    except Exception as e:
        print(f"[ERROR] è¼‰å…¥è³‡æ–™å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()
    
    
def get_database_stats() -> dict:
    """
    å–å¾—è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š
    
    Returns:
        dict: çµ±è¨ˆè³‡è¨Š
    """
    conn = get_db_connection()
    
    try:
        cursor = conn.cursor()
        
        stats = {}
        
        # å–å¾—å„è¡¨æ ¼çš„è¨˜éŒ„æ•¸
        tables = ['ifa_d005', 'ifa_d003', 'ifa_d004']
        
        for table in tables:
            cursor.execute(f"SELECT COUNT(*) as count FROM {table}")
            result = cursor.fetchone()
            stats[f'{table}_count'] = result['count'] if result else 0
            
            # å–å¾—å„æ¸¯å£çš„è¨˜éŒ„æ•¸
            cursor.execute(f"""
                SELECT port_code, COUNT(*) as count 
                FROM {table} 
                GROUP BY port_code
            """)
            port_stats = cursor.fetchall()
            stats[f'{table}_by_port'] = {row['port_code']: row['count'] for row in port_stats}
            
            # å–å¾—è²¨æ«ƒè¼ªè¨˜éŒ„æ•¸
            cursor.execute(f"""
                SELECT COUNT(*) as count 
                FROM {table} 
                WHERE can_berth_container = 1
            """)
            result = cursor.fetchone()
            stats[f'{table}_container_count'] = result['count'] if result else 0
            
            # ğŸ”¥ æª¢æŸ¥é‡è¤‡è¨˜éŒ„æ•¸
            if table == 'ifa_d005':
                unique_cols = 'port_code, wharf_code, vessel_ename, eta_berth'
            elif table == 'ifa_d003':
                unique_cols = 'port_code, vessel_ename, eta_berth'
            elif table == 'ifa_d004':
                unique_cols = 'port_code, vessel_ename, etd_berth'
            else:
                continue
            
            cursor.execute(f"""
                SELECT COUNT(*) - COUNT(DISTINCT {unique_cols}) as duplicate_count
                FROM {table}
            """)
            result = cursor.fetchone()
            stats[f'{table}_duplicate_count'] = result['duplicate_count'] if result else 0
        
        # å–å¾—è³‡æ–™åº«æª”æ¡ˆå¤§å°
        if os.path.exists(DB_PATH):
            stats['db_size_mb'] = round(os.path.getsize(DB_PATH) / (1024 * 1024), 2)
        else:
            stats['db_size_mb'] = 0
        
        return stats
        
    except Exception as e:
        logger.error(f"âœ— å–å¾—è³‡æ–™åº«çµ±è¨ˆå¤±æ•—: {e}")
        return {}
    
    finally:
        conn.close()

def get_table_columns(table_name: str) -> list:
    """
    å–å¾—è¡¨æ ¼çš„æ‰€æœ‰æ¬„ä½åç¨±
    
    Args:
        table_name: è¡¨æ ¼åç¨±
    
    Returns:
        list: æ¬„ä½åç¨±åˆ—è¡¨
    """
    conn = get_db_connection()
    
    try:
        cursor = conn.cursor()
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = [row[1] for row in cursor.fetchall()]
        return columns
        
    except sqlite3.Error as e:
        logger.error(f"âœ— å–å¾—è¡¨æ ¼æ¬„ä½å¤±æ•—: {e}")
        return []
    
    finally:
        conn.close()


# ==================== æ¸¬è©¦ç¨‹å¼ ====================

if __name__ == "__main__":
    print("=== æ¸¬è©¦è³‡æ–™åº«æ¨¡çµ„ï¼ˆæ•´åˆä¿®æ­£ç‰ˆ v3.0ï¼‰===\n")
    
    # åˆå§‹åŒ–è³‡æ–™åº«
    print("1. åˆå§‹åŒ–è³‡æ–™åº«...")
    init_database()
    
    # åŸ·è¡Œé·ç§»
    print("\n2. åŸ·è¡Œè³‡æ–™åº«é·ç§»...")
    migrate_database()
    
    # é¡¯ç¤ºè¡¨æ ¼æ¬„ä½
    print("\n3. é¡¯ç¤ºè¡¨æ ¼æ¬„ä½:")
    for table in ['ifa_d005', 'ifa_d003', 'ifa_d004']:
        columns = get_table_columns(table)
        print(f"\n{table} ({len(columns)} æ¬„ä½):")
        for i, col in enumerate(columns, 1):
            print(f"  {i:2d}. {col}")
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    print("\n4. è³‡æ–™åº«çµ±è¨ˆ:")
    stats = get_database_stats()
    for key, value in stats.items():
        if isinstance(value, dict):
            print(f"  {key}:")
            for k, v in value.items():
                print(f"    - {k}: {v}")
        else:
            print(f"  {key}: {value}")
    
    # æ¸¬è©¦é‡è¤‡è¨˜éŒ„ç§»é™¤
    print("\n5. æ¸¬è©¦é‡è¤‡è¨˜éŒ„ç§»é™¤:")
    results = remove_duplicate_records()
    for table, count in results.items():
        print(f"  {table}: ç§»é™¤ {count} ç­†é‡è¤‡è¨˜éŒ„")
    
    print("\nâœ“ æ¸¬è©¦å®Œæˆ")
